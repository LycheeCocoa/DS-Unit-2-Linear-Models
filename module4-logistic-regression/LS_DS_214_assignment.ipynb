{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "Lambda School Data Science\n",
    "\n",
    "*Unit 2, Sprint 1, Module 4*\n",
    "\n",
    "---"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 860,
   "source": [
    "%%capture\r\n",
    "\r\n",
    "import sys\r\n",
    "import pandas as pd\r\n",
    "import numpy as np\r\n",
    "\r\n",
    "from sklearn.model_selection import cross_val_score\r\n",
    "from sklearn.preprocessing import StandardScaler\r\n",
    "from sklearn.linear_model import LogisticRegression as lr\r\n",
    "from sklearn.impute import SimpleImputer\r\n",
    "from category_encoders import OneHotEncoder\r\n",
    "from sklearn.pipeline import make_pipeline\r\n",
    "# If you're on Colab:\r\n",
    "if 'google.colab' in sys.modules:\r\n",
    "    DATA_PATH = 'https://raw.githubusercontent.com/LambdaSchool/DS-Unit-2-Linear-Models/master/data/'\r\n",
    "    !pip install category_encoders==2.*\r\n",
    "\r\n",
    "# If you're working locally:\r\n",
    "else:\r\n",
    "    DATA_PATH = '../data/'\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Module Project: Logistic Regression\r\n",
    "\r\n",
    "Do you like burritos? ðŸŒ¯ You're in luck then, because in this project you'll create a model to predict whether a burrito is `'Great'`.\r\n",
    "\r\n",
    "The dataset for this assignment comes from [Scott Cole](https://srcole.github.io/100burritos/), a San Diego-based data scientist and burrito enthusiast. \r\n",
    "\r\n",
    "## Directions\r\n",
    "\r\n",
    "The tasks for this project are the following:\r\n",
    "\r\n",
    "- **Task 1:** Import `csv` file using `wrangle` function.\r\n",
    "- **Task 2:** Conduct exploratory data analysis (EDA), and modify `wrangle` function .\r\n",
    "- **Task 3:** Split data into feature matrix `X` and target vector `y`.\r\n",
    "- **Task 4:** Split feature matrix `X` and target vector `y` into training and test sets.\r\n",
    "- **Task 5:** Establish the baseline accuracy score for your dataset.\r\n",
    "- **Task 6:** Build `model_logr` using a pipeline that includes three transfomers and `LogisticRegression` predictor. Train model on `X_train` and `X_test`.\r\n",
    "- **Task 7:** Calculate the training and test accuracy score for your model.\r\n",
    "- **Task 8:** Create a horizontal bar chart showing the 10 most influencial features for your  model. \r\n",
    "- **Task 9:** Demonstrate and explain the differences between `model_lr.predict()` and `model_lr.predict_proba()`.\r\n",
    "\r\n",
    "**Note** \r\n",
    "\r\n",
    "You should limit yourself to the following libraries:\r\n",
    "\r\n",
    "- `category_encoders`\r\n",
    "- `matplotlib`\r\n",
    "- `pandas`\r\n",
    "- `sklearn`"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# I. Wrangle Data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 861,
   "source": [
    "\r\n",
    "def wrangle(filepath):\r\n",
    "    # Import w/ DateTimeIndex\r\n",
    "    df = pd.read_csv(filepath, parse_dates=['Date'],\r\n",
    "                     index_col='Date')\r\n",
    "\r\n",
    "    # Drop unrated burritos\r\n",
    "    df.dropna(subset=['overall'], inplace=True)\r\n",
    "\r\n",
    "    # Derive binary classification target:\r\n",
    "    # We define a 'Great' burrito as having an\r\n",
    "    # overall rating of 4 or higher, on a 5 point scale\r\n",
    "    df['Great'] = (df['overall'] >= 4).astype(int)\r\n",
    "\r\n",
    "    # Drop high cardinality categoricals\r\n",
    "    df = df.drop(columns=['Notes', 'Location',\r\n",
    "                 'Address', 'URL', 'Neighborhood'])\r\n",
    "\r\n",
    "    # Drop columns to prevent \"leakage\"\r\n",
    "    df = df.drop(columns=['Rec', 'overall'])\r\n",
    "    df = df.drop(columns=['Queso'])\r\n",
    "    return df\r\n",
    "\r\n",
    "\r\n",
    "filepath = DATA_PATH + 'burritos/burritos.csv'\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Task 1:** Use the above `wrangle` function to import the `burritos.csv` file into a DataFrame named `df`."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 862,
   "source": [
    "filepath = DATA_PATH + 'burritos/burritos.csv'\r\n",
    "df = wrangle(filepath)\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "During your exploratory data analysis, note that there are several columns whose data type is `object` but that seem to be a binary encoding. For example, `df['Beef'].head()` returns:\n",
    "\n",
    "```\n",
    "0      x\n",
    "1      x\n",
    "2    NaN\n",
    "3      x\n",
    "4      x\n",
    "Name: Beef, dtype: object\n",
    "```\n",
    "\n",
    "**Task 2:** Change the `wrangle` function so that these columns are properly encoded as `0` and `1`s. Be sure your code handles upper- and lowercase `X`s, and `NaN`s."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 863,
   "source": [
    "def encode(df):\r\n",
    "    list = ['x', 'X', 'Yes', 'No']\r\n",
    "    dict = {'x': '1', 'X': '1', 'Yes': '1', 'No': '0'}\r\n",
    "    if any(x in df.value_counts().index.to_list() for x in list):\r\n",
    "        df = df.map(dict)\r\n",
    "        df = df.fillna(0)\r\n",
    "    return df\r\n",
    "\r\n",
    "\r\n",
    "df = df.apply(encode)\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 874,
   "source": [
    "# Conduct your exploratory data analysis here\r\n",
    "# And modify the `wrangle` function above.\r\n",
    "\r\n",
    "#making sure I cleaned up all null valls\r\n",
    "for col in df:\r\n",
    "    if df[col].notnull().sum() != len(df):\r\n",
    "        if(df[col].dtype != ('float64' or 'int64')):\r\n",
    "            print(df[col].name)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Reviewer\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "If you explore the `'Burrito'` column of `df`, you'll notice that it's a high-cardinality categorical feature. You'll also notice that there's a lot of overlap between the categories. \r\n",
    "\r\n",
    "**Stretch Goal:** Change the `wrangle` function above so that it engineers four new features: `'california'`, `'asada'`, `'surf'`, and `'carnitas'`. Each row should have a `1` or `0` based on the text information in the `'Burrito'` column. For example, here's how the first 5 rows of the dataset would look.\r\n",
    "\r\n",
    "| **Burrito** | **california** | **asada** | **surf** | **carnitas** |\r\n",
    "| :---------- | :------------: | :-------: | :------: | :----------: |\r\n",
    "| California  |       1        |     0     |    0     |      0       |\r\n",
    "| California  |       1        |     0     |    0     |      0       |\r\n",
    "|  Carnitas   |       0        |     0     |    0     |      1       |\r\n",
    "| Carne asada |       0        |     1     |    0     |      0       |\r\n",
    "| California  |       1        |     0     |    0     |      0       |\r\n",
    "\r\n",
    "**Note:** Be sure to also drop the `'Burrito'` once you've engineered your new features."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 865,
   "source": [
    "# Conduct your exploratory data analysis here\r\n",
    "# And modify the `wrangle` function above.\r\n",
    "\r\n",
    "df.loc[df['Burrito'] == 'California', 'california'] = 1\r\n",
    "df.loc[df['Burrito'] != 'California', 'california'] = 0\r\n",
    "df['california'] = df['california'].astype(int)\r\n",
    "\r\n",
    "\r\n",
    "df.loc[df['Burrito'] == 'Carnitas', 'carnitas'] = 1\r\n",
    "df.loc[df['Burrito'] != 'Carnitas', 'carnitas'] = 0\r\n",
    "df['carnitas'] = df['carnitas'].astype(int)\r\n",
    "\r\n",
    "df.loc[df['Burrito'] == 'Carne asada', 'asada'] = 1\r\n",
    "df.loc[df['Burrito'] != 'Carne asada', 'asada'] = 0\r\n",
    "df['asada'] = df['asada'].astype(int)\r\n",
    "\r\n",
    "df.loc[df['Burrito'].str.contains('surf', case=False),'surf'] = 1\r\n",
    "df['surf'] = df['surf'].fillna(0)\r\n",
    "df['surf'] = df['surf'].astype(int)\r\n",
    "\r\n",
    "\r\n",
    "#pd.set_option(\"display.max_rows\", None, \"display.max_columns\", None)\r\n",
    "#df['Burrito'].value_counts()\r\n",
    "\r\n",
    "df.drop(columns='Burrito', inplace=True)\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# II. Split Data\n",
    "\n",
    "**Task 3:** Split your dataset into the feature matrix `X` and the target vector `y`. You want to predict `'Great'`."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 866,
   "source": [
    "X = df.drop(columns=['Great'])\r\n",
    "y = df['Great']"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Task 4:** Split `X` and `y` into a training set (`X_train`, `y_train`) and a test set (`X_test`, `y_test`).\n",
    "\n",
    "- Your training set should include data from 2016 through 2017. \n",
    "- Your test set should include data from 2018 and later."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 867,
   "source": [
    "train = (X.index.year <= 2017) & (X.index.year >= 2016)\r\n",
    "test = X.index.year >= 2018\r\n",
    "X_train, y_train = X[train], y[train]\r\n",
    "X_test, y_test = X[test], y[test]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# III. Establish Baseline\n",
    "\n",
    "**Task 5:** Since this is a **classification** problem, you should establish a baseline accuracy score. Figure out what is the majority class in `y_train` and what percentage of your training observations it represents. "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 868,
   "source": [
    "baseline_acc = y_train.value_counts(normalize=True).max()\r\n",
    "print('Baseline Accuracy Score:', baseline_acc)\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Baseline Accuracy Score: 0.5826771653543307\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# IV. Build Model\r\n",
    "\r\n",
    "**Task 6:** Build a `Pipeline` named `model_logr`, and fit it to your training data. Your pipeline should include:\r\n",
    "\r\n",
    "- a `OneHotEncoder` transformer for categorical features, \r\n",
    "- a `SimpleImputer` transformer to deal with missing values, \r\n",
    "- a [`StandarScaler`](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html) transfomer (which often improves performance in a logistic regression model), and \r\n",
    "- a `LogisticRegression` predictor."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 869,
   "source": [
    "model_logr = make_pipeline(OneHotEncoder(use_cat_names=True), SimpleImputer(\r\n",
    "    strategy='mean'), StandardScaler(), lr())\r\n",
    "\r\n",
    "model_logr.fit(X_train, y_train)\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\coco\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\category_encoders\\utils.py:21: FutureWarning: is_categorical is deprecated and will be removed in a future version.  Use is_categorical_dtype instead\n",
      "  elif pd.api.types.is_categorical(cols):\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Pipeline(steps=[('onehotencoder',\n",
       "                 OneHotEncoder(cols=['Chips', 'Reviewer', 'Unreliable', 'NonSD',\n",
       "                                     'Beef', 'Pico', 'Guac', 'Cheese', 'Fries',\n",
       "                                     'Sour cream', 'Pork', 'Chicken', 'Shrimp',\n",
       "                                     'Fish', 'Rice', 'Beans', 'Lettuce',\n",
       "                                     'Tomato', 'Bell peper', 'Carrots',\n",
       "                                     'Cabbage', 'Sauce', 'Salsa.1', 'Cilantro',\n",
       "                                     'Onion', 'Taquito', 'Pineapple', 'Ham',\n",
       "                                     'Chile relleno', 'Nopales', ...],\n",
       "                               use_cat_names=True)),\n",
       "                ('simpleimputer', SimpleImputer()),\n",
       "                ('standardscaler', StandardScaler()),\n",
       "                ('logisticregression', LogisticRegression())])"
      ]
     },
     "metadata": {},
     "execution_count": 869
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# IV. Check Metrics\n",
    "\n",
    "**Task 7:** Calculate the training and test accuracy score for `model_lr`."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 883,
   "source": [
    "training_acc = model_logr.score(X_train, y_train)\r\n",
    "test_acc = model_logr.score(X_test,y_test)\r\n",
    "print('Training MAE:', training_acc)\r\n",
    "print('Test MAE:', test_acc)\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training MAE: 0.9711286089238845\n",
      "Test MAE: 0.7894736842105263\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# V. Communicate Results\n",
    "\n",
    "**Task 8:** Create a horizontal barchart that plots the 10 most important coefficients for `model_lr`, sorted by absolute value.\n",
    "\n",
    "**Note:** Since you created your model using a `Pipeline`, you'll need to use the [`named_steps`](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html) attribute to access the coefficients in your `LogisticRegression` predictor. Be sure to look at the shape of the coefficients array before you combine it with the feature names."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 871,
   "source": [
    "pd.DataFrame(data=model_logr['logisticregression'].coef_.reshape(-1,\r\n",
    "             1), columns=['coefficient'], index=model_logr[0].get_feature_names()).abs().sort_values(by='coefficient').tail(10).plot(kind='barh')\r\n",
    "# Create your horizontal barchart here.\r\n"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "metadata": {},
     "execution_count": 871
    },
    {
     "output_type": "display_data",
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "There is more than one way to generate predictions with `model_lr`. For instance, you can use [`predict`](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html?highlight=logisticregression) or [`predict_proba`](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html?highlight=logisticregression#sklearn.linear_model.LogisticRegression.predict_proba).\n",
    "\n",
    "**Task 9:** Generate predictions for `X_test` using both `predict` and `predict_proba`. Then below, write a summary of the differences in the output for these two methods. You should answer the following questions:\n",
    "\n",
    "- What data type do `predict` and `predict_proba` output?\n",
    "- What are the shapes of their different output?\n",
    "- What numerical values are in the output?\n",
    "- What do those numerical values represent?"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 887,
   "source": [
    "# Write code here to explore the differences between `predict` and `predict_proba`.\r\n",
    "predict = model_logr.predict(X_train)\r\n",
    "predict_proba = model_logr.predict_proba(X_test)\r\n",
    "\r\n",
    "# percent of great burritos.\r\n",
    "predict.sum() / len(predict)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.4041994750656168"
      ]
     },
     "metadata": {},
     "execution_count": 887
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Give your written answer here:**\r\n",
    "\r\n",
    "```\r\n",
    "predict returns a np.array that predicts whether the burrito was great(1) or not(0). its shape should be the length of the training set\r\n",
    "\r\n",
    "predict_proba returns a np.array with the probability of whether or not the data belongs to class 0(not Great) to class 1(Great burrito). its shape should be two dimensional.\r\n",
    "```"
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "LS_DS_214_solution.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.6 64-bit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "interpreter": {
   "hash": "4b7a67c094ca4859574ab7812cb20959fc8d8ba5f9f349a7149ef35bab6b6336"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}